import type * as Vapi from "../index.mjs";
export interface SpeechmaticsTranscriber {
    /** This is the transcription provider that will be used. */
    provider: Vapi.SpeechmaticsTranscriberProvider;
    /** This is the model that will be used for the transcription. */
    model?: Vapi.SpeechmaticsTranscriberModel;
    language?: Vapi.SpeechmaticsTranscriberLanguage;
    /**
     * This is the operating point for the transcription. Choose between `standard` for faster turnaround with strong accuracy or `enhanced` for highest accuracy when precision is critical.
     *
     * @default 'enhanced'
     */
    operatingPoint?: Vapi.SpeechmaticsTranscriberOperatingPoint;
    /**
     * This is the region for the Speechmatics API. Choose between EU (Europe) and US (United States) regions for lower latency and data sovereignty compliance.
     *
     * @default 'eu'
     */
    region?: Vapi.SpeechmaticsTranscriberRegion;
    /**
     * This enables speaker diarization, which identifies and separates speakers in the transcription. Essential for multi-speaker conversations and conference calls.
     *
     * @default false
     */
    enableDiarization?: boolean;
    /**
     * This sets the maximum number of speakers to detect when diarization is enabled. Only used when enableDiarization is true.
     *
     * @default 2
     */
    maxSpeakers?: number;
    /** Provides friendly speaker labels that map to diarization indices (Speaker 1 -> labels[0]). */
    speakerLabels?: string[];
    /**
     * This enables partial transcripts during speech recognition. When false, only final transcripts are returned.
     *
     * @default true
     */
    enablePartials?: boolean;
    /**
     * This sets the maximum delay in milliseconds for partial transcripts. Balances latency and accuracy.
     *
     * @default 3000
     */
    maxDelay?: number;
    customVocabulary: Vapi.SpeechmaticsCustomVocabularyItem[];
    /**
     * This controls how numbers are formatted in the transcription output.
     *
     * @default 'written'
     */
    numeralStyle?: Vapi.SpeechmaticsTranscriberNumeralStyle;
    /**
     * This enables detection of non-speech audio events like music, applause, and laughter.
     *
     * @default false
     */
    enableEntities?: boolean;
    /**
     * This enables automatic punctuation in the transcription output.
     *
     * @default true
     */
    enablePunctuation?: boolean;
    /**
     * This enables automatic capitalization in the transcription output.
     *
     * @default true
     */
    enableCapitalization?: boolean;
    /**
     * This is the sensitivity level for end-of-turn detection, which determines when a speaker has finished talking. Higher values are more sensitive.
     *
     * @default 0.5
     */
    endOfTurnSensitivity?: number;
    /**
     * This enables removal of disfluencies (um, uh) from the transcript to create cleaner, more professional output.
     *
     * @default false
     */
    removeDisfluencies?: boolean;
    /**
     * This is the minimum duration in seconds for speech segments. Shorter segments will be filtered out. Helps remove noise and improve accuracy.
     *
     * @default 0.0
     */
    minimumSpeechDuration?: number;
    /** This is the plan for voice provider fallbacks in the event that the primary voice provider fails. */
    fallbackPlan?: Vapi.FallbackTranscriberPlan;
}
